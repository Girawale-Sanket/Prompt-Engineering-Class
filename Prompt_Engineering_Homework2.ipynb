{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "owcK-W7A3cgY",
        "outputId": "876d6d13-714c-4499-d122-626673f9907e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting langchain\n",
            "  Downloading langchain-0.2.14-py3-none-any.whl.metadata (7.1 kB)\n",
            "Collecting groq\n",
            "  Downloading groq-0.9.0-py3-none-any.whl.metadata (13 kB)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (6.0.2)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.0.32)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (3.10.5)\n",
            "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (4.0.3)\n",
            "Collecting langchain-core<0.3.0,>=0.2.32 (from langchain)\n",
            "  Downloading langchain_core-0.2.35-py3-none-any.whl.metadata (6.2 kB)\n",
            "Collecting langchain-text-splitters<0.3.0,>=0.2.0 (from langchain)\n",
            "  Downloading langchain_text_splitters-0.2.2-py3-none-any.whl.metadata (2.1 kB)\n",
            "Collecting langsmith<0.2.0,>=0.1.17 (from langchain)\n",
            "  Downloading langsmith-0.1.104-py3-none-any.whl.metadata (13 kB)\n",
            "Requirement already satisfied: numpy<2,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain) (1.26.4)\n",
            "Requirement already satisfied: pydantic<3,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.8.2)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.32.3)\n",
            "Collecting tenacity!=8.4.0,<9.0.0,>=8.1.0 (from langchain)\n",
            "  Downloading tenacity-8.5.0-py3-none-any.whl.metadata (1.2 kB)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from groq) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from groq) (1.7.0)\n",
            "Collecting httpx<1,>=0.23.0 (from groq)\n",
            "  Downloading httpx-0.27.0-py3-none-any.whl.metadata (7.2 kB)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from groq) (1.3.1)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.7 in /usr/local/lib/python3.10/dist-packages (from groq) (4.12.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (2.4.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (24.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.9.4)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->groq) (3.7)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->groq) (1.2.2)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->groq) (2024.7.4)\n",
            "Collecting httpcore==1.* (from httpx<1,>=0.23.0->groq)\n",
            "  Downloading httpcore-1.0.5-py3-none-any.whl.metadata (20 kB)\n",
            "Collecting h11<0.15,>=0.13 (from httpcore==1.*->httpx<1,>=0.23.0->groq)\n",
            "  Downloading h11-0.14.0-py3-none-any.whl.metadata (8.2 kB)\n",
            "Collecting jsonpatch<2.0,>=1.33 (from langchain-core<0.3.0,>=0.2.32->langchain)\n",
            "  Downloading jsonpatch-1.33-py2.py3-none-any.whl.metadata (3.0 kB)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.3.0,>=0.2.32->langchain) (24.1)\n",
            "Collecting orjson<4.0.0,>=3.9.14 (from langsmith<0.2.0,>=0.1.17->langchain)\n",
            "  Downloading orjson-3.10.7-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (50 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.4/50.4 kB\u001b[0m \u001b[31m711.7 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.20.1 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain) (2.20.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (3.3.2)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (2.0.7)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (3.0.3)\n",
            "Collecting jsonpointer>=1.9 (from jsonpatch<2.0,>=1.33->langchain-core<0.3.0,>=0.2.32->langchain)\n",
            "  Downloading jsonpointer-3.0.0-py2.py3-none-any.whl.metadata (2.3 kB)\n",
            "Downloading langchain-0.2.14-py3-none-any.whl (997 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m997.8/997.8 kB\u001b[0m \u001b[31m8.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading groq-0.9.0-py3-none-any.whl (103 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m103.5/103.5 kB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading httpx-0.27.0-py3-none-any.whl (75 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.6/75.6 kB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading httpcore-1.0.5-py3-none-any.whl (77 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.9/77.9 kB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langchain_core-0.2.35-py3-none-any.whl (394 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m394.9/394.9 kB\u001b[0m \u001b[31m17.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langchain_text_splitters-0.2.2-py3-none-any.whl (25 kB)\n",
            "Downloading langsmith-0.1.104-py3-none-any.whl (149 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m149.1/149.1 kB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tenacity-8.5.0-py3-none-any.whl (28 kB)\n",
            "Downloading jsonpatch-1.33-py2.py3-none-any.whl (12 kB)\n",
            "Downloading orjson-3.10.7-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (141 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m141.9/141.9 kB\u001b[0m \u001b[31m9.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading jsonpointer-3.0.0-py2.py3-none-any.whl (7.6 kB)\n",
            "Installing collected packages: tenacity, orjson, jsonpointer, h11, jsonpatch, httpcore, httpx, langsmith, groq, langchain-core, langchain-text-splitters, langchain\n",
            "  Attempting uninstall: tenacity\n",
            "    Found existing installation: tenacity 9.0.0\n",
            "    Uninstalling tenacity-9.0.0:\n",
            "      Successfully uninstalled tenacity-9.0.0\n",
            "Successfully installed groq-0.9.0 h11-0.14.0 httpcore-1.0.5 httpx-0.27.0 jsonpatch-1.33 jsonpointer-3.0.0 langchain-0.2.14 langchain-core-0.2.35 langchain-text-splitters-0.2.2 langsmith-0.1.104 orjson-3.10.7 tenacity-8.5.0\n",
            "Collecting langchain-groq\n",
            "  Downloading langchain_groq-0.1.9-py3-none-any.whl.metadata (2.9 kB)\n",
            "Requirement already satisfied: groq in /usr/local/lib/python3.10/dist-packages (0.9.0)\n",
            "Requirement already satisfied: langchain-core<0.3.0,>=0.2.26 in /usr/local/lib/python3.10/dist-packages (from langchain-groq) (0.2.35)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from groq) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from groq) (1.7.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from groq) (0.27.0)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from groq) (2.8.2)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from groq) (1.3.1)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.7 in /usr/local/lib/python3.10/dist-packages (from groq) (4.12.2)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->groq) (3.7)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->groq) (1.2.2)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->groq) (2024.7.4)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->groq) (1.0.5)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->groq) (0.14.0)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.3.0,>=0.2.26->langchain-groq) (6.0.2)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.3.0,>=0.2.26->langchain-groq) (1.33)\n",
            "Requirement already satisfied: langsmith<0.2.0,>=0.1.75 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.3.0,>=0.2.26->langchain-groq) (0.1.104)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.3.0,>=0.2.26->langchain-groq) (24.1)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<9.0.0,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.3.0,>=0.2.26->langchain-groq) (8.5.0)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->groq) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.20.1 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->groq) (2.20.1)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.10/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.3.0,>=0.2.26->langchain-groq) (3.0.0)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.2.0,>=0.1.75->langchain-core<0.3.0,>=0.2.26->langchain-groq) (3.10.7)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.2.0,>=0.1.75->langchain-core<0.3.0,>=0.2.26->langchain-groq) (2.32.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langsmith<0.2.0,>=0.1.75->langchain-core<0.3.0,>=0.2.26->langchain-groq) (3.3.2)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langsmith<0.2.0,>=0.1.75->langchain-core<0.3.0,>=0.2.26->langchain-groq) (2.0.7)\n",
            "Downloading langchain_groq-0.1.9-py3-none-any.whl (14 kB)\n",
            "Installing collected packages: langchain-groq\n",
            "Successfully installed langchain-groq-0.1.9\n",
            "Collecting openai\n",
            "  Downloading openai-1.42.0-py3-none-any.whl.metadata (22 kB)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai) (1.7.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from openai) (0.27.0)\n",
            "Collecting jiter<1,>=0.4.0 (from openai)\n",
            "  Downloading jiter-0.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.6 kB)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from openai) (2.8.2)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.10/dist-packages (from openai) (4.66.5)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.11 in /usr/local/lib/python3.10/dist-packages (from openai) (4.12.2)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (3.7)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (1.2.2)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai) (2024.7.4)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai) (1.0.5)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.14.0)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.20.1 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (2.20.1)\n",
            "Downloading openai-1.42.0-py3-none-any.whl (362 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m362.9/362.9 kB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading jiter-0.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (318 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m318.9/318.9 kB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: jiter, openai\n",
            "Successfully installed jiter-0.5.0 openai-1.42.0\n"
          ]
        }
      ],
      "source": [
        "!pip install langchain groq\n",
        "!pip install langchain-groq groq\n",
        "!pip install openai"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q1 Implement a Chain-of-Thought prompting system to solve word problems. Your system should\n",
        "break down the problem-solving process into steps and show its reasoning.\n",
        "Task:\n",
        "● Create a function that takes a word problem as input.\n",
        "● Use the OpenAI API or any other LLM API to generate a step-by-step solution.\n",
        "● The output should show each step of the reasoning process.\n",
        "● Test your function with at least two word problems of varying complexity.\n",
        "Example word problem: \"A baker has 150 eggs. If each cake requires 3 eggs and each cookie\n",
        "requires 2 eggs, how many cakes and cookies can the baker make if they want to use all the\n",
        "eggs and make an equal number of each?\""
      ],
      "metadata": {
        "id": "8PuH1loy5nxK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_groq import ChatGroq\n",
        "from langchain.chains import LLMChain, SimpleSequentialChain\n",
        "from langchain_core.messages import AIMessage, HumanMessage, SystemMessage\n",
        "from langchain.prompts import Prompt\n",
        "from langchain import PromptTemplate, LLMChain\n",
        "import os\n",
        "\n",
        "# Set your Groq API key\n",
        "os.environ[\"GROQ_API_KEY\"] = \"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\"\n",
        "\n",
        "# Initialize the Groq LLM\n",
        "llm = ChatGroq(model_name=\"mixtral-8x7b-32768\")\n",
        ""
      ],
      "metadata": {
        "id": "e9Zyx-QL3rYE"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "example = \"\"\"\n",
        "Question:\" Sean buys 25 stickers on Monday and 17 on Tuesday. On Wednesday, he gives 5/6\n",
        " th of his stickers to James. How many does he have left?\"\n",
        "\n",
        "\"\"\"\n",
        "human_message = HumanMessage(content=example)\n",
        "system_message = SystemMessage(content=\"You are helpful assistant.\")\n",
        "\n",
        "\n",
        "new_prompt = (system_message + human_message)\n",
        "\n",
        "print (f\"Prompt: {new_prompt}\")\n",
        "\n",
        "chain = LLMChain(llm=llm, prompt=new_prompt)\n",
        "reponse = chain.run({})\n",
        "print(f\"Response: {reponse}\")\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9l9anmFq328i",
        "outputId": "83e2624b-da83-47ac-968a-8fdba91a79ba"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Prompt: input_variables=[] messages=[SystemMessage(content='You are helpful assistant.'), HumanMessage(content='\\nQuestion:\" Sean buys 25 stickers on Monday and 17 on Tuesday. On Wednesday, he gives 5/6\\n th of his stickers to James. How many does he have left?\"\\n\\n')]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/langchain_core/_api/deprecation.py:151: LangChainDeprecationWarning: The class `LLMChain` was deprecated in LangChain 0.1.17 and will be removed in 1.0. Use RunnableSequence, e.g., `prompt | llm` instead.\n",
            "  warn_deprecated(\n",
            "/usr/local/lib/python3.10/dist-packages/langchain_core/_api/deprecation.py:151: LangChainDeprecationWarning: The method `Chain.run` was deprecated in langchain 0.1.0 and will be removed in 1.0. Use invoke instead.\n",
            "  warn_deprecated(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Response: First, let's find out how many stickers Sean had in total after buying on Monday and Tuesday:\n",
            "\n",
            "Monday + Tuesday = 25 (stickers bought on Monday) + 17 (stickers bought on Tuesday) = 42 stickers\n",
            "\n",
            "Next, we need to calculate how many stickers Sean gave to James on Wednesday. We know he gave 5/6 of his stickers, so:\n",
            "\n",
            "Stickers given to James = Total stickers * (5/6)\n",
            "                                      = 42 * (5/6)\n",
            "                                      = 35\n",
            "\n",
            "Finally, to find out how many stickers Sean has left, we subtract the number of stickers he gave to James from his total:\n",
            "\n",
            "Stickers remaining = Total stickers - Stickers given to James\n",
            "                             = 42 - 35\n",
            "                             = 7\n",
            "\n",
            "So, Sean has 7 stickers left after giving 5/6 of his stickers to James.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "example=\"\"\"\n",
        "Question:\"Mr. Thomas sold 832 cookies in January and 917 cookies in February. How many cookies did he sell in these two months?\"\n",
        "\"\"\"\n",
        "\n",
        "human_message = HumanMessage(content=example)\n",
        "system_message = SystemMessage(content=\"You are helpful assistant.\")\n",
        "\n",
        "\n",
        "new_prompt = (system_message + human_message)\n",
        "\n",
        "print (f\"Prompt: {new_prompt}\")\n",
        "\n",
        "chain = LLMChain(llm=llm, prompt=new_prompt)\n",
        "reponse = chain.run({})\n",
        "print(f\"Response: {reponse}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UHjeXdr34KSZ",
        "outputId": "49b16e56-f5b0-46c9-bf70-b2ce14fa8969"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Prompt: input_variables=[] messages=[SystemMessage(content='You are helpful assistant.'), HumanMessage(content='\\nQuestion:\"Mr. Thomas sold 832 cookies in January and 917 cookies in February. How many cookies did he sell in these two months?\"\\n')]\n",
            "Response: To find out how many cookies Mr. Thomas sold in January and February, you simply need to add the number of cookies he sold each month.\n",
            "\n",
            "Here's the calculation:\n",
            "\n",
            "January + February = Total cookies sold\n",
            "832 + 917 = 1749\n",
            "\n",
            "So, Mr. Thomas sold a total of 1749 cookies in January and February.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q 2)Develop a prompt-chaining system that generates a short story based on user input. The system should use multiple prompts in sequence, with each prompt building on the output of the previous one. Task: ● Create a series of at least 3 prompts that will be chained together. ● The first prompt should ask for a genre and main character. ● Subsequent prompts should build on previous outputs to develop the plot and conclusion. ● Implement the chaining logic to pass information between prompts. ● Allow the user to input the initial genre and main character. ● Output the final story generated through the chain"
      ],
      "metadata": {
        "id": "0UmiomB14e7c"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "system_message = SystemMessage(content=\"You are a creative assistant for generating short stories.\")\n",
        "\n",
        "# Prompt 1: Get genre and main character\n",
        "initial_prompt = HumanMessage(content=\"Provide a genre and a main character for a short story.\")\n",
        "\n",
        "# Create the chain and get the genre and character\n",
        "chain1 = LLMChain(llm=llm, prompt=system_message + initial_prompt)\n",
        "response1 = chain1.run({})\n",
        "\n",
        "try:\n",
        "    genre, character = response1.split(', ')\n",
        "except ValueError as e:\n",
        "    print(f\"Error parsing response: {e}\")\n",
        "    genre, character = None, None\n",
        "\n",
        "\n",
        "response1 = \"Action, Avengers:End Game \"\n",
        "print(f\"Genre: {genre}, \\nCharacter: {character}\")\n",
        "\n",
        "\n",
        "plot_prompt = HumanMessage(content=f\"Based on the genre '{genre}' and the main character '{character}', write a brief plot outline for a short story.\")\n",
        "\n",
        "\n",
        "chain2 = LLMChain(llm=llm, prompt=system_message + plot_prompt)\n",
        "plot = chain2.run({})\n",
        "\n",
        "\n",
        "conclusion_prompt = HumanMessage(content=f\"Based on the plot outline provided, write the conclusion for the short story.\")\n",
        "\n",
        "\n",
        "chain3 = LLMChain(llm=llm, prompt=system_message + conclusion_prompt)\n",
        "conclusion = chain3.run({})\n",
        "\n",
        "\n",
        "final_story = f\"Genre: {genre}\\nMain Character: {character}\\nPlot: {plot}\\nConclusion: {conclusion}\"\n",
        "print(final_story)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dfW8hFus4gWC",
        "outputId": "bf75aecd-6d78-4614-862f-4b4b830109b5"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error parsing response: too many values to unpack (expected 2)\n",
            "Genre: None, \n",
            "Character: None\n",
            "Genre: None\n",
            "Main Character: None\n",
            "Plot: Title: The Infinite Blank\n",
            "\n",
            "In a world where creativity is the only source of energy, there exists a solitary character, known simply as The Writer. The Writer has the unique ability to create entire universes and characters with a single stroke of their pen. However, they are suffering from a crippling case of writer's block. \n",
            "\n",
            "The Writer's once-vibrant and bustling city now lies in ruins, drained of life and color due to the lack of new stories. The citizens, who were once inspired and full of imagination, now wander aimlessly, awaiting their creator's return to the blank page. \n",
            "\n",
            "Desperate to restore their world, The Writer embarks on a journey through the remnants of their own creations, seeking inspiration from the characters they've brought to life. Along the way, they encounter past heroes and villains, each pleading for their own continuation. \n",
            "\n",
            "The Writer realizes that the solution lies not in the external world, but within themselves. They return to the blank page, and instead of trying to force a story, they embrace the void. In doing so, they discover an infinite well of inspiration and creativity, and the world around them bursts back to life, filled with the wonders of an endless supply of stories.\n",
            "Conclusion: Plot Outline:\n",
            "\n",
            "In a world where people can choose to be reincarnated into any form they desire, a young woman named Lily decides to become a tree. She wants to experience the slow pace of life and the connection to nature that comes with being a living organism deeply rooted in the earth.\n",
            "\n",
            "Years pass, and Lily becomes a magnificent, ancient tree, home to many creatures and a witness to the changing seasons. One day, a young girl named Mia discovers Lily and forms a strong bond with her. Mia visits Lily every day, sharing her stories and dreams. Lily, in turn, provides Mia with wisdom and a sense of peace.\n",
            "\n",
            "Conclusion:\n",
            "\n",
            "As the years went by, Mia grew older, and Lily remained the eternal, unchanging tree. Mia's visits became less frequent, but she always returned, knowing that Lily would be there, listening and offering solace.\n",
            "\n",
            "One winter day, Mia, now an old woman, visited Lily for the last time. She sat by the tree, her frail body wrapped in a warm shawl, and whispered her final goodbyes. Lily felt a deep sadness, but she also knew that this was part of the cycle of life.\n",
            "\n",
            "Mia passed away that night, her spirit joining the vast expanse of the universe. Lily, the ancient tree, stood tall and strong, her branches reaching towards the heavens. She had been a part of Mia's life, and now she would continue to be a silent observer, a symbol of resilience and the eternal connection between all living beings.\n",
            "\n",
            "And so, Lily the tree, once a young woman seeking solace in the slow pace of nature, became a testament to the beauty of life and the enduring power of love and friendship.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q3)Implement a Tree-of-Thought prompting system to solve a complex problem. The system should explore multiple paths of reasoning and select the most promising one. Task: ● Create a function that takes a complex problem as input. ● Generate at least 3 different initial approaches to solving the problem. ● For each approach, develop 2-3 possible next steps. ● Implement a method to evaluate the promise of each path. ● Select the most promising path and generate a final solution. ● Test your system with the following problem: Problem: \"Design a sustainable urban transportation system for a city of 1 million people. Consider factors such as environmental impact, cost-effectiveness, and accessibility for all residents"
      ],
      "metadata": {
        "id": "3E8rJo6b5BUa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "first_prompt = PromptTemplate(\n",
        "    input_variables=[\"topic\"],\n",
        "    template=\"Write a short introduction about {topic}.\"\n",
        ")\n",
        "\n",
        "# Second prompt template\n",
        "second_prompt = PromptTemplate(\n",
        "    input_variables=[\"introduction\"],\n",
        "    template=\"Based on this introduction, suggest 3 key points to expand upon: {introduction}\"\n",
        ")\n",
        "\n",
        "# Third prompt template\n",
        "third_prompt = PromptTemplate(\n",
        "    input_variables=[\"key_points\"],\n",
        "    template=\"For each of these key points, provide a brief explanation: {key_points}\"\n",
        ")\n",
        "\n",
        "# Create chains\n",
        "chain_one = LLMChain(llm=llm, prompt=first_prompt)\n",
        "chain_two = LLMChain(llm=llm, prompt=second_prompt)\n",
        "chain_three = LLMChain(llm=llm, prompt=third_prompt)\n",
        "\n",
        "# Create the sequential chain\n",
        "overall_chain = SimpleSequentialChain(\n",
        "    chains=[chain_one, chain_two, chain_three],\n",
        "    verbose=True\n",
        ")\n",
        "\n",
        "# Run the chain\n",
        "topic = \"future of ai in data science\"\n",
        "result = overall_chain.run(topic)\n",
        "\n",
        "print(result)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ofb5m7bW5CcT",
        "outputId": "0544ca5d-9109-4d29-c755-e8a3beca108f"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new SimpleSequentialChain chain...\u001b[0m\n",
            "\u001b[36;1m\u001b[1;3mThe future of AI in data science is promising, with the potential to revolutionize the way we analyze and interpret data. With the ability to learn from data and improve over time, AI algorithms are becoming increasingly accurate and efficient. In the coming years, we can expect AI to play a larger role in data preprocessing, predictive modeling, and automating data science workflows. Additionally, the integration of AI with other emerging technologies, such as blockchain and the Internet of Things (IoT), will create new opportunities for data analysis and decision-making. However, it is important to address the ethical and societal implications of AI in data science, such as bias, privacy, and job displacement, to ensure that these technologies are used responsibly and for the benefit of all.\u001b[0m\n",
            "\u001b[33;1m\u001b[1;3m1. AI in data preprocessing: AI can significantly improve data preprocessing, which is a critical step in data science as it involves cleaning, transforming, and organizing data to make it suitable for analysis. AI algorithms can automate data cleansing, detect anomalies, and suggest data transformations, thereby reducing manual effort, increasing accuracy, and accelerating the data preprocessing process.\n",
            "\n",
            "2. AI in predictive modeling: AI has the potential to enhance predictive modeling by enabling the development of more accurate and complex models. With its ability to learn from data, AI can identify patterns and relationships that are not easily discernible by humans. This can lead to the creation of predictive models that are more precise and better equipped to handle large and complex datasets. Moreover, AI can automate the feature engineering process, further improving the predictive modeling process.\n",
            "\n",
            "3. Ethical and societal implications of AI: While the potential benefits of AI in data science are significant, it is crucial to consider the ethical and societal implications of these technologies. Issues such as bias, privacy, and job displacement need to be addressed to ensure that AI is used responsibly and for the benefit of all. Bias can occur in AI models due to the data used to train them, leading to unfair or discriminatory outcomes. Privacy concerns arise from the use of personal data in AI models, and there is a risk of job displacement as AI automates data science workflows. Addressing these issues requires a collaborative effort from stakeholders, including data scientists, policymakers, and society at large.\u001b[0m\n",
            "\u001b[38;5;200m\u001b[1;3m1. AI in data preprocessing: AI can greatly enhance data preprocessing, a vital step in data science, by automating data cleansing, anomaly detection, and data transformation tasks. These capabilities reduce the need for manual intervention, increase accuracy, and speed up the overall preprocessing process. By leveraging AI algorithms, data scientists can ensure that their datasets are clean, reliable, and properly formatted, which ultimately leads to more accurate and insightful analysis.\n",
            "\n",
            "2. AI in predictive modeling: AI has the capacity to significantly improve predictive modeling through the creation of more precise and intricate models. With its ability to learn from data, AI can identify patterns and relationships that might not be readily apparent to human analysts. This capability allows data scientists to construct predictive models that are better equipped to handle large, complex datasets and deliver more accurate predictions. Additionally, AI can automate the feature engineering process, further streamlining the predictive modeling workflow and enabling data scientists to focus on higher-level tasks.\n",
            "\n",
            "3. Ethical and societal implications of AI: As AI continues to play an increasingly prominent role in data science, it is crucial to consider the ethical and societal implications of these technologies. Issues such as bias, privacy, and job displacement need to be addressed to ensure that AI is used responsibly and for the benefit of all. Bias can manifest in AI models due to the data used for training, leading to discriminatory or unfair outcomes. Privacy concerns arise from the use of personal data in AI models, and there is a risk of job displacement as AI automates data science workflows. Addressing these challenges requires a concerted effort from stakeholders, including data scientists, policymakers, and society at large, to ensure that AI is developed and deployed ethically and responsibly.\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "1. AI in data preprocessing: AI can greatly enhance data preprocessing, a vital step in data science, by automating data cleansing, anomaly detection, and data transformation tasks. These capabilities reduce the need for manual intervention, increase accuracy, and speed up the overall preprocessing process. By leveraging AI algorithms, data scientists can ensure that their datasets are clean, reliable, and properly formatted, which ultimately leads to more accurate and insightful analysis.\n",
            "\n",
            "2. AI in predictive modeling: AI has the capacity to significantly improve predictive modeling through the creation of more precise and intricate models. With its ability to learn from data, AI can identify patterns and relationships that might not be readily apparent to human analysts. This capability allows data scientists to construct predictive models that are better equipped to handle large, complex datasets and deliver more accurate predictions. Additionally, AI can automate the feature engineering process, further streamlining the predictive modeling workflow and enabling data scientists to focus on higher-level tasks.\n",
            "\n",
            "3. Ethical and societal implications of AI: As AI continues to play an increasingly prominent role in data science, it is crucial to consider the ethical and societal implications of these technologies. Issues such as bias, privacy, and job displacement need to be addressed to ensure that AI is used responsibly and for the benefit of all. Bias can manifest in AI models due to the data used for training, leading to discriminatory or unfair outcomes. Privacy concerns arise from the use of personal data in AI models, and there is a risk of job displacement as AI automates data science workflows. Addressing these challenges requires a concerted effort from stakeholders, including data scientists, policymakers, and society at large, to ensure that AI is developed and deployed ethically and responsibly.\n"
          ]
        }
      ]
    }
  ]
}